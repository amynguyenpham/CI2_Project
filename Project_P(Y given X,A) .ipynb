{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9xfL3OqE09fO"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers datasets accelerate\n",
        "import transformers\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/MyDrive/train_with_topics.csv')\n",
        "df = df[['text', 'topic_label', 'hate_label']].dropna()\n",
        "df['hate_label'] = df['hate_label'].astype(int)\n"
      ],
      "metadata": {
        "id": "lpmVATWq1Ns0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ],
      "metadata": {
        "id": "aNmH7TZE2XWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_text(row):\n",
        "df['input_text'] = df.apply(combine_text, axis=1)\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "train_dataset = Dataset.from_pandas(train_df[['input_text', 'hate_label']])\n",
        "val_dataset = Dataset.from_pandas(val_df[['input_text', 'hate_label']])\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"input_text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.rename_column(\"hate_label\", \"labels\")\n",
        "val_dataset = val_dataset.rename_column(\"hate_label\", \"labels\")\n",
        "\n",
        "train_dataset.set_format(\"torch\")\n",
        "val_dataset.set_format(\"torch\")\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/hate_model_conditional\",\n",
        "    do_eval=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_dir=\"/content/logs\",\n",
        "    logging_steps=100,\n",
        "    save_steps=500,\n",
        "    eval_steps=500,\n",
        "    save_total_limit=1\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "id": "9JeoVbcN12Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/drive/MyDrive/hate_model_conditional\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/hate_model_conditional\")\n"
      ],
      "metadata": {
        "id": "snMR69TiEuRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Dy-3tjd_HuT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}