{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jaE7DS0DKaNz"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers datasets accelerate\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import transformers\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ],
      "metadata": {
        "id": "14Y0ZH6uLAQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Only use the input text and hate label\n",
        "df = pd.read_csv('/content/drive/MyDrive/train_with_topics.csv')\n",
        "df = df[['text', 'topic_label', 'hate_label']].dropna()\n",
        "df['hate_label'] = df['hate_label'].astype(int)\n",
        "\n",
        "# Split into train/test\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n",
        "\n",
        "# Convert to Hugging Face dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "full_dataset = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "id": "ZGnceOoCMdgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def tokenize(example):\n",
        "    return tokenizer(example['text'], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize, batched=True)\n",
        "full_dataset = full_dataset.map(tokenize, batched=True)\n",
        "\n",
        "train_dataset = train_dataset.rename_column(\"hate_label\", \"labels\")\n",
        "val_dataset = val_dataset.rename_column(\"hate_label\", \"labels\")\n",
        "full_dataset = full_dataset.rename_column(\"hate_label\", \"labels\")\n",
        "\n",
        "train_dataset.set_format(\"torch\")\n",
        "val_dataset.set_format(\"torch\")\n",
        "full_dataset.set_format(\"torch\")\n"
      ],
      "metadata": {
        "id": "N_M-0DDLMrnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/hate_model_basic_full_dataset\",\n",
        "    save_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=10,\n",
        "    logging_dir=\"/content/logs\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train and evaluate\n",
        "trainer.train()\n",
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "id": "Up0f2HoLMwdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running model in-domain on Twitter dataset\n",
        "# Load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Load test CSV\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/train.csv\")\n",
        "\n",
        "# Batch size for prediction\n",
        "batch_size = 32\n",
        "\n",
        "# Get the device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)  # Ensure model is on the correct device\n",
        "\n",
        "# Store predictions\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "\n",
        "# Iterate over the data in batches\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch = df[i : i + batch_size]\n",
        "\n",
        "    test_encodings = tokenizer(\n",
        "        batch[\"text\"].tolist(),\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**test_encodings)\n",
        "        probs = torch.softmax(outputs.logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_probs.extend(probs.cpu().numpy().tolist())\n",
        "\n",
        "# Add predictions to DataFrame\n",
        "df[\"predicted_label\"] = all_preds\n",
        "df[\"predicted_prob\"] = all_probs\n",
        "\n",
        "# Calculate accuracy\n",
        "correct = (df[\"predicted_label\"] == df[\"hate_label\"]).sum()\n",
        "accuracy = correct / len(df)\n",
        "\n",
        "# Print results\n",
        "print(df[[\"text\", \"hate_label\", \"predicted_label\"]].head())\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "NvS1MHAqND3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running model out of domain on Reddit dataset\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Load test CSV\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/test_reddit.csv\")\n",
        "\n",
        "# Get the device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)  # Ensure model is on the correct device\n",
        "\n",
        "# Batch size for prediction\n",
        "batch_size = 32\n",
        "\n",
        "# Store predictions\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "\n",
        "# Iterate over the data in batches\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch = df[i : i + batch_size]\n",
        "\n",
        "    test_encodings = tokenizer(\n",
        "        batch[\"text\"].tolist(),\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**test_encodings)\n",
        "        probs = torch.softmax(outputs.logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_probs.extend(probs.cpu().numpy().tolist())\n",
        "\n",
        "# Add predictions to DataFrame\n",
        "df[\"predicted_label\"] = all_preds\n",
        "df[\"predicted_prob\"] = all_probs\n",
        "\n",
        "# Calculate accuracy\n",
        "correct = (df[\"predicted_label\"] == df[\"hate_label\"]).sum()\n",
        "accuracy = correct / len(df)\n",
        "\n",
        "# Print results\n",
        "print(df[[\"text\", \"hate_label\", \"predicted_label\"]].head())\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "CphAVDcyP1kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Running model out of domain on Youtube dataset\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Load test CSV\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/test_youtube.csv\")\n",
        "\n",
        "# Batch size for prediction\n",
        "batch_size = 32\n",
        "\n",
        "# Store predictions\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "\n",
        "# Iterate over the data in batches\n",
        "for i in range(0, len(df), batch_size):\n",
        "    batch = df[i : i + batch_size]\n",
        "\n",
        "    test_encodings = tokenizer(\n",
        "        batch[\"text\"].tolist(),\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**test_encodings)\n",
        "        probs = torch.softmax(outputs.logits, dim=1)\n",
        "        preds = torch.argmax(probs, dim=1)\n",
        "\n",
        "    all_preds.extend(preds.cpu().numpy())\n",
        "    all_probs.extend(probs.cpu().numpy().tolist())\n",
        "\n",
        "# Add predictions to DataFrame\n",
        "df[\"predicted_label\"] = all_preds\n",
        "df[\"predicted_prob\"] = all_probs\n",
        "\n",
        "# Calculate accuracy\n",
        "correct = (df[\"predicted_label\"] == df[\"hate_label\"]).sum()\n",
        "accuracy = correct / len(df)\n",
        "\n",
        "# Print results\n",
        "print(df[[\"text\", \"hate_label\", \"predicted_label\"]].head())\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "5Hbm1-_V1Vwl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}